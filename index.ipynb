{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "#run this cell as-is\n", "import pandas as pd\n", "import numpy as np\n", "from sklearn.datasets import make_classification\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.metrics import f1_score\n", "\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "#used for tests\n", "from test_scripts.test_class import Test\n", "test = Test()\n", "\n", "data = test.load_ind('data')\n", "\n", "X = data.drop('target', axis=1, inplace=False)\n", "y = data['target']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Complete the following code which:\n", "\n", "- Performs a train-test split\n", "  - test data is 20% of total data, `random_state` of 34\n", "\n", "- creates StandardScaler and KnnClassifier objects\n", "\n", "- scales the train and test data (correctly!)\n", "\n", "- Sets up a loop which\n", "  - sets the `n_neighbors` attribute in the knn object to the current iteration of the loop\n", "     - (Why do we only include odd k values?  Why do we start with 3?)\n", "  - fits the knn object on the training data\n", "  - makes predictions on the test data\n", "  - finds the f1_score of the test data\n", "  - appends that score to `knn_scores`, a hither-to empty list\n", "  \n", "The code following the loop graphs the f1_score by k value, no need to alter anything in there\n", "\n", "Graph should look like this:\n", "\n", "![](test_obj/viz.png)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=34)\n", "\n", "scaler = StandardScaler()\n", "knn = KNeighborsClassifier()\n", "\n", "X_train_scl = scaler.fit_transform(X_train)\n", "X_test_scl = scaler.transform(X_test)\n", "\n", "knn_scores = []\n", "\n", "for k in range(3,20,2):\n", "\n", "    knn = knn.set_params(n_neighbors=k)\n", "    \n", "    knn.fit(X_train_scl, y_train)\n", "    knn_preds = knn.predict(X_test_scl)\n", "    \n", "    knn_score = f1_score(y_test, knn_preds)\n", "    \n", "    knn_scores.append(knn_score)\n", "    \n", "fig, ax = plt.subplots()\n", "ax.plot([x for x in range(3,20, 2)], knn_scores)\n", "ax.set_xticks([x for x in range(3,20, 2)])\n", "ax.set_xlabel('k')\n", "ax.set_ylabel('test f1 score')\n", "ax.set_title('test f1 score for odd values of k')\n", "plt.savefig('test_obj/viz')\n", "plt.plot();"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Which value of k should we choose as our model?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "'''\n", "Not obvious when it's not a well-behaved curve, right?  \n", "If we were to choose k based purely on f1 score, we could choose 13.\n", "However, if we wanted to have the lowest possible k, 11 would be a more optimal choice.\n", "'''"]}], "metadata": {"kernelspec": {"display_name": "mlearn", "language": "python", "name": "mlearn"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.7"}}, "nbformat": 4, "nbformat_minor": 4}